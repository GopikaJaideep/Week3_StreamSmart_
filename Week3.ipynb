{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7f9208d-05e7-4fc3-a2cf-209d2205d614",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data = [\n",
    "    # valid\n",
    "    {\"user_id\": \"U001\", \"status\": \"Active\", \"date\": \"2025-08-01\", \"monthly_fee\": 16.99, \"age\": 24},\n",
    "    # invalid age (negative)\n",
    "    {\"user_id\": \"U002\", \"status\": \"Inactive\", \"date\": \"2025-01-15\", \"monthly_fee\": 27.99, \"age\": -7},\n",
    "    # missing user_id\n",
    "    {\"user_id\": None, \"status\": \"Active\", \"date\": \"2026-02-03\", \"monthly_fee\": 49.99, \"age\": 30},\n",
    "    # duplicate user_id\n",
    "    {\"user_id\": \"U001\", \"status\": \"ACTIVE\", \"date\": \"2025-02-04\", \"monthly_fee\": 16.99, \"age\": 28},\n",
    "    # valid\n",
    "    {\"user_id\": \"U003\", \"status\": \"inactive\", \"date\": \"2025-11-20\", \"monthly_fee\": None, \"age\": 22},\n",
    "    # invalid age (string)\n",
    "    {\"user_id\": \"U004\", \"status\": \"Active\", \"date\": \"2025-12-05\", \"monthly_fee\": 27.99, \"age\": \"twenty\"},\n",
    "    # missing user_id\n",
    "    {\"user_id\": None, \"status\": \"Inactive\", \"date\": \"2025-09-25\", \"monthly_fee\": 23.99, \"age\": 35},\n",
    "    # duplicate user_id\n",
    "    {\"user_id\": \"U003\", \"status\": \"Active\", \"date\": \"2025-12-06\", \"monthly_fee\": 44.99, \"age\": 40},\n",
    "    # valid\n",
    "    {\"user_id\": \"U005\", \"status\": \"Inactive\", \"date\": \"2026-01-30\", \"monthly_fee\": 28.99, \"age\": 27},\n",
    "    # unrealistic age\n",
    "    {\"user_id\": \"U006\", \"status\": \"Active\", \"date\": \"2025-12-02\", \"monthly_fee\": 17.99, \"age\": 250},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(raw_data)\n",
    "df.to_csv(\"subscription.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e81118f-088d-463b-a445-282f81a21d5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Clean and validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dbd8f69-98fc-4785-b0a6-37ca12509d9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Standardise status to lowercase\n",
    "df[\"status\"] = df[\"status\"].str.lower()\n",
    "\n",
    "# Convert date columns to proper datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Replace missing monthly_fee with the median fee\n",
    "median_fee = df[\"monthly_fee\"].median()\n",
    "df[\"monthly_fee\"] = df[\"monthly_fee\"].fillna(median_fee)\n",
    "\n",
    "# Ensure age is numeric (invalid → NaN)\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "df.loc[(df[\"age\"] < 0) | (df[\"age\"] > 120), \"age\"] = None\n",
    "\n",
    "# Drop records where user_id is missing or duplicated\n",
    "df = df.dropna(subset=[\"user_id\"])\n",
    "df = df.drop_duplicates(subset=[\"user_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2b37b4f-4e39-42b0-bb93-cdab78863c3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Engineer new analytical features and answer business questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdd52698-a102-49c8-af9f-344d22b17970",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# subscription_length_days\n",
    "from datetime import datetime\n",
    "\n",
    "today = pd.Timestamp(\"2026-02-06\")\n",
    "df[\"subscription_length_days\"] = (today - df[\"date\"]).dt.days\n",
    "\n",
    "# is_active_subscription (1/0)\n",
    "df[\"is_active_subscription\"] = (df[\"status\"] == \"active\").astype(int)\n",
    "\n",
    "# revenue_estimate = monthly_fee × months_active\n",
    "df[\"months_active\"] = (df[\"subscription_length_days\"] / 30).astype(int) # months_active\n",
    "df[\"revenue_estimate\"] = df[\"monthly_fee\"] * df[\"months_active\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57f21960-10ae-459a-b4de-ccc7e43314ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Integrate an external public API with error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6380db6c-70a3-4d40-9341-e076c2a703eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Simple country codes\n",
    "df[\"country_code\"] = df[\"user_id\"].apply(\n",
    "    lambda x: \"AU\" if x in [\"U001\", \"U002\"] else \"US\" if x in [\"U003\", \"U004\"] else \"IN\"\n",
    ")\n",
    "\n",
    "# Call public API\n",
    "try:\n",
    "    response = requests.get(\n",
    "        \"https://restcountries.com/v3.1/alpha?codes=AU,US,IN\",\n",
    "        timeout=5\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    countries = response.json()\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"API error:\", e)\n",
    "    countries = []\n",
    "\n",
    "# Build lookup dictionary\n",
    "country_lookup = {\n",
    "    c[\"cca2\"]: c[\"name\"][\"common\"]\n",
    "    for c in countries\n",
    "    if \"cca2\" in c and \"name\" in c\n",
    "}\n",
    "\n",
    "# Map country names to dataframe\n",
    "df[\"country_name\"] = df[\"country_code\"].map(country_lookup)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89e43c68-e18d-47cb-90f4-e5396c05f7fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load cleaned data into a relational database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46d64e99-4359-42ae-bdc6-2f2e4501dae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Column, String, Integer, Float, Date\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "\n",
    "# Create SQLite database\n",
    "engine = create_engine(\"sqlite:///streamsmart.db\", echo=False)\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define tables\n",
    "class User(Base):\n",
    "    __tablename__ = \"users\"\n",
    "    user_id = Column(String, primary_key=True)\n",
    "    age = Column(Integer)\n",
    "    country_code = Column(String(2))\n",
    "    country_name = Column(String)\n",
    "\n",
    "class Subscription(Base):\n",
    "    __tablename__ = \"subscriptions\"\n",
    "    user_id = Column(String, primary_key=True)\n",
    "    status = Column(String)\n",
    "    start_date = Column(Date)\n",
    "    monthly_fee = Column(Float)\n",
    "    is_active_subscription = Column(Integer)\n",
    "    months_active = Column(Integer)\n",
    "    revenue_estimate = Column(Float)\n",
    "\n",
    "class AnalyticsSummary(Base):\n",
    "    __tablename__ = \"analytics_summary\"\n",
    "    country_code = Column(String(2), primary_key=True)\n",
    "    country_name = Column(String)\n",
    "    user_count = Column(Integer)\n",
    "    total_revenue = Column(Float)\n",
    "    active_subscriptions = Column(Integer)\n",
    "\n",
    "# Create tables (drop first to avoid duplicates)\n",
    "Base.metadata.drop_all(engine)\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Insert USERS table\n",
    "users = [\n",
    "    User(\n",
    "        user_id=row[\"user_id\"],\n",
    "        age=None if pd.isna(row[\"age\"]) else int(row[\"age\"]),\n",
    "        country_code=row[\"country_code\"],\n",
    "        country_name=row[\"country_name\"]\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "session.bulk_save_objects(users)\n",
    "session.commit()\n",
    "\n",
    "# Insert SUBSCRIPTIONS table\n",
    "subscriptions = [\n",
    "    Subscription(\n",
    "        user_id=row[\"user_id\"],\n",
    "        status=row[\"status\"],\n",
    "        start_date=row[\"date\"].date(),\n",
    "        monthly_fee=float(row[\"monthly_fee\"]),\n",
    "        is_active_subscription=int(row[\"is_active_subscription\"]),\n",
    "        months_active=int(row[\"months_active\"]),\n",
    "        revenue_estimate=float(row[\"revenue_estimate\"])\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "session.bulk_save_objects(subscriptions)\n",
    "session.commit()\n",
    "\n",
    "# Build & insert ANALYTICS SUMMARY table\n",
    "summary_df = df.groupby(\n",
    "    [\"country_code\", \"country_name\"]\n",
    ").agg(\n",
    "    user_count=(\"user_id\", \"count\"),\n",
    "    total_revenue=(\"revenue_estimate\", \"sum\"),\n",
    "    active_subscriptions=(\"is_active_subscription\", \"sum\")\n",
    ").reset_index()\n",
    "\n",
    "summaries = [\n",
    "    AnalyticsSummary(\n",
    "        country_code=row[\"country_code\"],\n",
    "        country_name=row[\"country_name\"],\n",
    "        user_count=int(row[\"user_count\"]),\n",
    "        total_revenue=float(row[\"total_revenue\"]),\n",
    "        active_subscriptions=int(row[\"active_subscriptions\"])\n",
    "    )\n",
    "    for _, row in summary_df.iterrows()\n",
    "]\n",
    "session.bulk_save_objects(summaries)\n",
    "session.commit()\n",
    "\n",
    "# Verification\n",
    "print(\"Users:\", session.query(User).count())\n",
    "print(\"Subscriptions:\", session.query(Subscription).count())\n",
    "print(\"Analytics rows:\", session.query(AnalyticsSummary).count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f23d52e-5b28-4c3b-9d8a-6da0139746d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read tables from SQLite using pandas\n",
    "users_df = pd.read_sql(\"SELECT * FROM users\", engine)\n",
    "subscriptions_df = pd.read_sql(\"SELECT * FROM subscriptions\", engine)\n",
    "analytics_df = pd.read_sql(\"SELECT * FROM analytics_summary\", engine)\n",
    "\n",
    "# Print tables\n",
    "print(\"\\nUSERS TABLE\")\n",
    "print(users_df)\n",
    "\n",
    "print(\"\\nSUBSCRIPTIONS TABLE\")\n",
    "print(subscriptions_df)\n",
    "\n",
    "print(\"\\nANALYTICS SUMMARY TABLE\")\n",
    "print(analytics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02fd67ca-0096-41b0-9010-9b3669d9df15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"subscription_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a227f34-d054-4cc5-8e1d-a80b4edf95a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Questions to Answer\n",
    "1. When is it better to drop records vs. impute values, and how does this depend on business context?\n",
    "  - It is better to drop records when key information (like user_id) is missing or duplicated, because the record cannot be trusted.\n",
    "  - It is better to impute values when only non-critical data is missing and enough similar data exists, such as replacing a missing fee with the median.\n",
    "2. What assumptions are you making when estimating revenue this way, and how could they bias conclusions?\n",
    "  - The revenue estimate assumes users are billed every month and remain subscribed for the full calculated period.\n",
    "  - This may overestimate revenue if users cancel early, pause subscriptions, or receive discounts.\n",
    "3. Why should API failures not crash a data pipeline?\n",
    "  - APIs are external services and can fail due to network or service issues.\n",
    "  - If a pipeline crashes because of an API failure, the entire data process stops, so error handling ensures the pipeline continues to run safe\n",
    "4. Why is schema design just as important as data cleaning?\n",
    "  - Schema design ensures data is stored with correct types, keys, and structure.\n",
    "  - Without a proper schema, even clean data can become inconsistent, duplicated, or unreliable.\n",
    "5. How does version control improve trust in data outputs?\n",
    "  - Version control tracks all changes made to data and code.\n",
    "  - This allows results to be reproduced, audited, and rolled back, which increases trust in the final outputs."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Week3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
