Week 3 
StreamSmart Data Pipeline Case Study

Context / Business Scenario

You have just joined StreamSmart, a mid-sized subscription-based digital content company operating in Australia. StreamSmart offers monthly subscriptions and tracks user engagement, payments, and customer support activity.

The business wants to:
- Consolidate data from multiple sources
- Clean and standardise messy raw data
- Perform basic analysis to support decision-making
- Prepare a lightweight data pipeline that can later be automated

In this assignment, you will design and implement a small-scale data pipeline using Python. The goal is to simulate a real-world data engineering scenario involving data ingestion, cleaning, analysis, API integration, and database loading.

Learning Objectives
- Use Python for data collection, cleaning, and automation
- Work with CSV and JSON data formats
- Apply Pandas and NumPy for data manipulation
- Consume external APIs with error handling
- Load structured data into a relational database
- Apply Git and Linux command-line fundamentals
